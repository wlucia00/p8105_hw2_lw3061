P8105 HW2
================
Lucia Wang (lw3061)
due 10-04-2023

``` r
library(tidyverse)
```

    ## ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──
    ## ✔ dplyr     1.1.3     ✔ readr     2.1.4
    ## ✔ forcats   1.0.0     ✔ stringr   1.5.0
    ## ✔ ggplot2   3.4.3     ✔ tibble    3.2.1
    ## ✔ lubridate 1.9.2     ✔ tidyr     1.3.0
    ## ✔ purrr     1.0.2     
    ## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
    ## ✖ dplyr::filter() masks stats::filter()
    ## ✖ dplyr::lag()    masks stats::lag()
    ## ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors

``` r
library(readxl)
```

# Problem 1

## clean data in pols-month.csv

Use separate() to break up the variable mon into integer variables year,
month, and day; replace month number with month name; create a president
variable taking values gop and dem, and remove prez_dem and prez_gop;
and remove the day variable.

## clean data in snp.csv

arrange according to year and month, and organize so that year and month
are the leading columns.

## tidy unemployment data

this process will involve switching from “wide” to “long” format;
ensuring that key variables have the same name; and ensuring that key
variables take the same values.

## merge snp and pols and merge unemployment into the result

Write a short paragraph about these datasets. Explain briefly what each
dataset contained, and describe the resulting dataset (e.g. give the
dimension, range of years, and names of key variables).

# Problem 2

### Read and clean the Mr. Trash Wheel sheet.

1)  specify the sheet and omit rows with notes/figures and columns with
    notes

``` r
mrtrash_df = 
  read_excel("202207 Trash Wheel Collection Data.xlsx", 
             sheet="Mr. Trash Wheel", 
             range="A2:M549")
```

2)  clean and update the data to include a new `homes_powered` variable.
    Add an additional variable to keep track of which Trash Wheel is
    which…

``` r
mrtrash_df =
  janitor::clean_names(mrtrash_df) |>
  mutate(kilowatts = weight_tons * 500,
         homes_powered = kilowatts / 30,
         name = "Mr. Trash Wheel") 
```

3)  repeat for Professor Trash Wheel and Gwynnda, then combine

``` r
proftrash_df =
  read_excel("202207 Trash Wheel Collection Data.xlsx", 
             sheet="Professor Trash Wheel", 
             range="A2:L96") |>
  janitor::clean_names() |>
  mutate(kilowatts = weight_tons * 500,
         homes_powered = kilowatts / 30,
         name = "Professor Trash Wheel",
         year = as.character(year)) 

proftrash_df
```

    ## # A tibble: 94 × 15
    ##    dumpster month    year  date                weight_tons volume_cubic_yards
    ##       <dbl> <chr>    <chr> <dttm>                    <dbl>              <dbl>
    ##  1        1 January  2017  2017-01-02 00:00:00        1.79                 15
    ##  2        2 January  2017  2017-01-30 00:00:00        1.58                 15
    ##  3        3 February 2017  2017-02-26 00:00:00        2.32                 18
    ##  4        4 February 2017  2017-02-26 00:00:00        3.72                 15
    ##  5        5 February 2017  2017-02-28 00:00:00        1.45                 15
    ##  6        6 March    2017  2017-03-30 00:00:00        1.71                 15
    ##  7        7 April    2017  2017-04-01 00:00:00        1.82                 15
    ##  8        8 April    2017  2017-04-20 00:00:00        2.37                 15
    ##  9        9 May      2017  2017-05-10 00:00:00        2.64                 15
    ## 10       10 May      2017  2017-05-26 00:00:00        2.78                 15
    ## # ℹ 84 more rows
    ## # ℹ 9 more variables: plastic_bottles <dbl>, polystyrene <dbl>,
    ## #   cigarette_butts <dbl>, glass_bottles <dbl>, grocery_bags <dbl>,
    ## #   chip_bags <dbl>, kilowatts <dbl>, homes_powered <dbl>, name <chr>

``` r
gwynnda_df = 
  read_excel("202207 Trash Wheel Collection Data.xlsx", 
             sheet="Gwynnda Trash Wheel", 
             range="A2:J108") |>
  janitor::clean_names() |>
  mutate(kilowatts = weight_tons * 500,
         homes_powered = kilowatts / 30,
         name = "Gwynnda Trash Wheel",
         year = as.character(year))

gwynnda_df
```

    ## # A tibble: 106 × 13
    ##    dumpster month  year  date                weight_tons volume_cubic_yards
    ##       <dbl> <chr>  <chr> <dttm>                    <dbl>              <dbl>
    ##  1        1 July   2021  2021-07-03 00:00:00        0.93                 15
    ##  2        2 July   2021  2021-07-07 00:00:00        2.26                 15
    ##  3        3 July   2021  2021-07-07 00:00:00        1.62                 15
    ##  4        4 July   2021  2021-07-16 00:00:00        1.76                 15
    ##  5        5 July   2021  2021-07-30 00:00:00        1.53                 15
    ##  6        6 August 2021  2021-08-11 00:00:00        2.06                 15
    ##  7        7 August 2021  2021-08-14 00:00:00        1.9                  15
    ##  8        8 August 2021  2021-08-16 00:00:00        2.16                 15
    ##  9        9 August 2021  2021-08-16 00:00:00        2.6                  15
    ## 10       10 August 2021  2021-08-17 00:00:00        3.21                 15
    ## # ℹ 96 more rows
    ## # ℹ 7 more variables: plastic_bottles <dbl>, polystyrene <dbl>,
    ## #   cigarette_butts <dbl>, plastic_bags <dbl>, kilowatts <dbl>,
    ## #   homes_powered <dbl>, name <chr>

``` r
trashwheels_tidy_df =
  bind_rows(mrtrash_df, proftrash_df, gwynnda_df) |>
  janitor::clean_names()
```

The final tidied dataset with all 3 trash wheels incorporated has 17
columns (variables) and 747 rows (observations).

Key variables are `weight_tons`, `homes_powered`, `dumpster`, and
`month`/`year`/`date`. Some of the most popular trash items were
`cigarette_butts`, `plastic_bottles`, and `polystyrene`, but others like
`sports_balls` and `plastic_bags` were also present.

The total weight of trash collected by Professor Trash Wheel was 190.12
tons.

The total number of cigarette butts collected by Gwynnda in July 2021
was 8.1 tons.

# Problem 3

### Import and clean MCI data.

1)  import the data and clean names

``` r
baseline_df = 
  read_csv("data_mci/MCI_baseline.csv", skip=1) |>
  janitor::clean_names() 
```

    ## Rows: 483 Columns: 6
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (1): Age at onset
    ## dbl (5): ID, Current Age, Sex, Education, apoe4
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

The data currently has 483 observations.

2)  recode variables and remove participants who did not have an age of
    onset of MCI

``` r
baseline_df = baseline_df |>
  mutate(
    sex = as.character(sex),
    sex = case_match(sex, 
                     "0" ~ "Female",
                     "1" ~ "Male"),
    apoe4 = as.character(apoe4),
    apoe4 = case_match(apoe4,
                       "0" ~ "Non-carrier",
                       "1" ~ "Carrier"),
    id = as.character(id)
        ) |>
  filter(age_at_onset!=".") 
```

The number of observations that had an age of onset for MCI was 97.

The average baseline age of this final dataset was 65.61 years.

The proportion of women in the study who were APOE4 carriers was 0.65.

3)  import, clean, and tidy the biomarkers csv

``` r
amyloid_df = 
  read_csv("data_mci/mci_amyloid.csv", skip=1) |>
  janitor::clean_names()
```

    ## Rows: 487 Columns: 6
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (5): Baseline, Time 2, Time 4, Time 6, Time 8
    ## dbl (1): Study ID
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

Before cleaning out missing time values, the total number of
observations in the amyloid dataset is 487.

``` r
amyloid_df = amyloid_df |>
  drop_na() |>
  rename(id=study_id) |>
  mutate(
    id = as.character(id)
  )
```

After dropping missing values, the number of observations is 347.

4)  see which participants appear in which datasets, and then combine
    them and only retain participants in both.

``` r
anti_combine_1 = 
  anti_join(baseline_df, amyloid_df, by="id")

anti_combine_2 = 
  anti_join(amyloid_df, baseline_df, by="id")
```

31 participants only appeared in the baseline dataset, and 281
participants only appeared in the amyloid dataset.

``` r
mci_amyloid_combine = 
  inner_join(baseline_df, amyloid_df, by="id")
```

The final tidied dataset combining baseline and amyloid data only had
full data for 66 participants.

The average age at baseline for this group was 65.83 years, and the
average age of onset for MCI was NA.

Of these participants, 33 were women.

The proportion of participants who were carriers of the APOE4 variant
was 0.58.

5)  Export the data to the directory.

``` r
write_csv(mci_amyloid_combine, "data_mci/combined_mci_amyloid.csv")
```
