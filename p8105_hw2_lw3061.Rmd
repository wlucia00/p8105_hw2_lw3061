---
title: "P8105 HW2"
author: "Lucia Wang (lw3061)"
date: "due 10-04-2023"
output: github_document
---
```{r}
library(tidyverse)
library(readxl)
```

# Problem 1

## clean data in pols-month.csv
Use separate() to break up the variable mon into integer variables year, month, and day; replace month number with month name; create a president variable taking values gop and dem, and remove prez_dem and prez_gop; and remove the day variable.

## clean data in snp.csv 
arrange according to year and month, and organize so that year and month are the leading columns.

## tidy unemployment data
this process will involve switching from “wide” to “long” format; ensuring that key variables have the same name; and ensuring that key variables take the same values.

## merge snp and pols and merge unemployment into the result
Write a short paragraph about these datasets. Explain briefly what each dataset contained, and describe the resulting dataset (e.g. give the dimension, range of years, and names of key variables).

# Problem 2
Read and clean the Mr. Trash Wheel sheet.

1) specify the sheet and omit rows with notes/figures and columns with notes
```{r}
mrtrash_df = 
  read_excel("202207 Trash Wheel Collection Data.xlsx", 
             sheet="Mr. Trash Wheel", 
             range="A2:M549")
```

2) clean and update the data to include a new `homes_powered` variable. Add an additional variable to keep track of which Trash Wheel is which...
```{r}
mrtrash_df =
  janitor::clean_names(mrtrash_df) |>
  mutate(kilowatts = weight_tons * 500,
         homes_powered = kilowatts / 30,
         name = "Mr. Trash Wheel") 
```

3) repeat for Professor Trash Wheel and Gwynnda, then combine
```{r}
proftrash_df =
  read_excel("202207 Trash Wheel Collection Data.xlsx", 
             sheet="Professor Trash Wheel", 
             range="A2:L96") |>
  janitor::clean_names() |>
  mutate(kilowatts = weight_tons * 500,
         homes_powered = kilowatts / 30,
         name = "Professor Trash Wheel",
         year = as.character(year)) 

proftrash_df

gwynnda_df = 
  read_excel("202207 Trash Wheel Collection Data.xlsx", 
             sheet="Gwynnda Trash Wheel", 
             range="A2:J108") |>
  janitor::clean_names() |>
  mutate(kilowatts = weight_tons * 500,
         homes_powered = kilowatts / 30,
         name = "Gwynnda Trash Wheel",
         year = as.character(year))

gwynnda_df

trashwheels_tidy_df =
  bind_rows(mrtrash_df, proftrash_df, gwynnda_df) |>
  janitor::clean_names()

```

The final tidied dataset with all 3 trash wheels incorporated has `r ncol(trashwheels_tidy_df)` columns (variables) and `r nrow(trashwheels_tidy_df)` rows (observations). 

Key variables are `weight_tons`, `homes_powered`, `dumpster`, and `month`/`year`/`date`. Some of the most popular trash items were `cigarette_butts`, `plastic_bottles`, and `polystyrene`, but others like `sports_balls` and `plastic_bags` were also present. 

The total weight of trash collected by Professor Trash Wheel was `r sum(pull(proftrash_df, weight_tons))` tons. 

The total number of cigarette butts collected by Gwynnda in July 2021 was `r sum(pull(filter(gwynnda_df, month=="July", year=="2021"),weight_tons))` tons.


# Problem 3
## Import, clean, and tidy the dataset of baseline demographics. 
Ensure that sex and APOE4 carrier status are appropriate encoded (i.e. not numeric), and remove any participants who do not meet the stated inclusion criteria (i.e. no MCI at baseline). 

Discuss important steps in the import process and relevant features of the dataset. 

How many participants were recruited, and of these how many develop MCI? 

What is the average baseline age? What proportion of women in the study are APOE4 carriers?

## Similarly, import, clean, and tidy the dataset of longitudinally observed biomarker values; 
comment on the steps on the import process and the features of the dataset.

## Check whether some participants appear in only the baseline or amyloid datasets, and comment on your findings. 

## Combine the demographic and biomarker datasets so that only participants who appear in both datasets are retained, and briefly describe the resulting dataset; 
export the result as a CSV to your data directory